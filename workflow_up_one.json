{
  "1": {
    "inputs": {
      "ckpt_name": "realvisxlV40_v40LightningBakedvae.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "2": {
    "inputs": {
      "image": "but_one_00025_.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "3": {
    "inputs": {
      "upscale_by": [
        "7",
        2
      ],
      "seed": 121344886683785,
      "steps": 8,
      "cfg": 2,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 0.2,
      "mode_type": "Linear",
      "tile_width": 1024,
      "tile_height": 1024,
      "mask_blur": 8,
      "tile_padding": 32,
      "seam_fix_mode": "None",
      "seam_fix_denoise": 1,
      "seam_fix_width": 64,
      "seam_fix_mask_blur": 8,
      "seam_fix_padding": 16,
      "force_uniform_tiles": true,
      "tiled_decode": false,
      "image": [
        "2",
        0
      ],
      "model": [
        "15",
        0
      ],
      "positive": [
        "4",
        0
      ],
      "negative": [
        "5",
        0
      ],
      "vae": [
        "1",
        2
      ],
      "upscale_model": [
        "12",
        0
      ]
    },
    "class_type": "UltimateSDUpscale",
    "_meta": {
      "title": "Ultimate SD Upscale"
    }
  },
  "4": {
    "inputs": {
      "text": "",
      "clip": [
        "15",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "5": {
    "inputs": {
      "text": "",
      "clip": [
        "15",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "6": {
    "inputs": {
      "filename_prefix": "up_one",
      "images": [
        "3",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "7": {
    "inputs": {
      "desiredXSIZE": [
        "9",
        0
      ],
      "desiredYSIZE": [
        "11",
        0
      ]
    },
    "class_type": "RecommendedResCalc",
    "_meta": {
      "title": "Recommended Resolution Calculator"
    }
  },
  "8": {
    "inputs": {
      "image": [
        "2",
        0
      ]
    },
    "class_type": "CM_NearestSDXLResolution",
    "_meta": {
      "title": "NearestSDXLResolution"
    }
  },
  "9": {
    "inputs": {
      "op": "Mul",
      "a": [
        "8",
        0
      ],
      "b": 2
    },
    "class_type": "CM_IntBinaryOperation",
    "_meta": {
      "title": "IntBinaryOperation"
    }
  },
  "11": {
    "inputs": {
      "op": "Mul",
      "a": [
        "8",
        1
      ],
      "b": 2
    },
    "class_type": "CM_IntBinaryOperation",
    "_meta": {
      "title": "IntBinaryOperation"
    }
  },
  "12": {
    "inputs": {
      "model_name": "4x-UltraSharp.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "13": {
    "inputs": {
      "lora_name": "Nature SDXL.safetensors",
      "strength_model": 0.9,
      "strength_clip": 0.9,
      "model": [
        "1",
        0
      ],
      "clip": [
        "1",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "14": {
    "inputs": {
      "lora_name": "dreamcolor.safetensors",
      "strength_model": 1,
      "strength_clip": 1,
      "model": [
        "13",
        0
      ],
      "clip": [
        "13",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "15": {
    "inputs": {
      "lora_name": "gorden_city.safetensors",
      "strength_model": 0.9,
      "strength_clip": 0.9,
      "model": [
        "14",
        0
      ],
      "clip": [
        "14",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  }
}